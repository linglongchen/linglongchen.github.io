# 并发编程基础


作者： 陈汤姆
<br/>博客：[https://github.com/linglongchen/linglongchen.github.io](https://github.com/linglongchen/linglongchen.github.io)

>自我学习的积累！😄



## 基础概念

### 线程
CPU调度的基本单位
### 进程
操作系统资源分配的基本单位
### 死锁
- 互斥：线程对已经获取到的资源会排斥其它线程的使用，也就是该资源同时只能由一个线程占用
- 不可剥夺：线程获得资源之后就不可被其它线程抢占
- 占用且等待： 一个线程持有了一个资源但是又请求其它资源，而其它资源正在被其它线程占用，因此当前线程就会阻塞
- 循环请求： 是由一个线程请求资源的环形链造成的。也就是t0等待t1的资源

### 并发
并发是指多个任务或事件在宏观上似乎同时发生，针对访问的资源是同一个，即多个请求同时访问同一个资源


### 并行
由多个任务由不同的处理器或核心同时执行。并行通常发生在多核处理器或多处理器系统中
### volatile
- 如果一个字段被声明为volatile，那么Java线程内存模型确保所有线程看到这个变量的值是一致的
- 被volatile修饰的变量不对被重排序
#### 原理
- 增加volatile修饰的字段，底层会增加一个Lock前缀的汇编指令，该指令会将当前处理器缓存的数据写回到系统内存
- 每个CPU处理器通过**嗅探**在总线上的传播数据来检查自己的缓存是否过期
- 写回内存的操作会使其它CPU里缓存的内存地址失效
#### 特性
- 原子性：i++的方式不具备原子性
- 可见性
- 禁止重排序


### synchronized

#### 锁的场景
- 用在普通方法上:
	- 锁的是当前实例对象
	- 底层通过使用ACC_SYNCHRONIZED
- 用在静态同步方法
	- 锁的是当前类的Class对象
	- 底层通过使用ACC_SYNCHRONIZED
- 用在同步代码块
	- 锁的是括号里面配置的对象
	- 底层通过monitorenter和monitorexit实现
#### 原理
- Java使用对象头存储锁的信息，本质是线程获取对象中的监视器锁

#### 特性
- 原子性
- 可见性
- 有序性
- 可重入性

 
#### 锁升级
##### 无锁
##### 偏向锁
- 不存在锁竞争时，并且占用锁的通常是一个线程
-  在对象头中的记录偏向锁标记，以及持有偏向锁的线程ID
- 如果出现锁竞争，则偏向锁会升级
##### 轻量级锁
- 出现锁竞争，但是竞争只有少量线程之间的竞争
- 通过对象头记录轻量级锁
- 通过CAS获取锁，通过这种自旋的方式获得锁，超过自旋的次数依然没有获取到锁，则会升级为重量级锁
- 自旋一般默认为10次，但是现在是自适应自旋锁，会根据上一次的结果做优化
##### 重量级锁
- 直接锁对象或者实例
- 线程获取不到锁则直接等待

### Java内存模型
#### 概念
- 内存模型决定了一个线程对共享变量的写入何时对另外的线程可见
- 内存模型抽象了线程与主内存之间的关系
-  线程之间的共享数据存在主内存中
- 每个线程都有自己的本地内存（缓冲区），本地内存存储了线程共享变量的副本
#### 方案
##### 内存可见性
通过主内存的可见性提供多线程场景下的变量共享
#####  顺序一致性
 理想化的模型，通过保障执行顺序的一致性提供多线程的执行
#### 重排序
- 编译器重排序
- 指令重排序
- 内存系统重排序
#### 内存屏障
-  LoadLoad
	- P1 LoadLoad P2： P1的数据加载早于Load2的数据加载
- StoreStore
	- P1 StoreStore P2：P1的数据对其它处理器可见早于P2
-  LoadStore
	- P1 LoadStore P2： P1的数据加载早于P2
- StoreLoad
	- P1 StoreLoad P2： P1对其它处理器可见早于P2

#### 规则
#####  happens-before
- 前一个操作的结果对后一个操作可见： 保障内存可见性
##### as if serial
- 存在数据依赖关系的指令避免被重排序

### 线程之间的等待和通知
#### Object级别
- wait： 该对象的线程会被阻塞挂起
- notify：唤醒该对象下wait状态的线程，等待CPU调度
- notifyAll：唤醒所有该对象下wait状态的线程
#### Thread级别
- sleep：让线程睡眠的方法，让出CPU执行权，但是线程依然保持
- yield：让出CPU执行权的方法，线程被分配干其它事情
- join：等待线程执行终止的方法


### 锁
####  悲观锁
- 悲观锁是数据对外界的修改保持保守的态度，认为数据会被其它线程修改，所以每次对数据做处理时都会加锁，并且处理数据过程中数据也处于锁定状态。
- Java中的synchronized锁以及lock锁都是悲观锁
#### 乐观锁
- 乐观锁相对于悲观锁来说，认为数据在一般情况下并不会造成冲突，所以访问数据时并不会加入排他锁，而是在数据提交更新时，才会对验证数据是否冲突。
- 乐观锁的实现方式有CAS，以及版本控制（添加version字段来控制更新次数）
#### 公平锁
- 公平锁时指线程获取锁的顺序是按照线程请求锁的顺序来执行的，也就是先请求锁的线程先获得锁
- ReentrantLock提供了公平锁
#### 非公平锁
- 非公平锁是在运行时进行竞争，谁竞争到锁就是谁的，也就是先来不一定先得
- ReentrantLock也提供了非公平锁的实现方式;synchronized也是非公平锁
#### 共享锁
- 共享锁是可以由多个线程持有。共享锁其实是一种乐观锁，放宽了加锁的条件，允许多个线程同时操作
#### 独占锁
- 独占锁是任何时候都只有一个线程可以得到锁，独占锁是一种悲观锁，每次访问资源都会先加上互斥锁，这样限制了并发性
#### 自旋锁
- 自旋锁是当线程获取锁时，如果发现锁已经被其它线程占用，它不马上阻塞自己，在不放弃CPU使用权的情况下，多次尝试获取锁
- synchronized中的轻量级锁就是通过自旋锁实现的
- 自旋锁不会使线程状态发生切换
#### 可重入锁
- 如果一个线程获得了锁，那么这个线程就可以无限次数的进入被该锁锁住的代码
- synchronized内部锁是可重入锁